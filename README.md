# 4DX@HOME - あなたの世界で「最高の映像」が「最強の体験」へ。

![4DX@HOME](assets/images/4DX@HOME.png)

## 製品概要
### 背景(製品開発のきっかけ、課題等）
スマートフォンでの動画視聴が主流になる中、小さい画面では得にくい「没入感」が課題となっています。映画館の4DXのような体感型エンターテインメントは大掛かりな機材が必要で、自宅での視聴体験は画一的なものにとどまっていました。

### 製品説明（具体的な製品の説明）
4DX@HOMEは、スマートフォンでの動画視聴に「触覚」「香り」などの物理フィードバックを加えることで、「観る」から「体感する」へと視聴体験を革新するシステムです。WebSocketによるリアルタイム通信で動画と物理デバイスを高精度に同期させ、手のひらサイズの4DXシアターを実現します。

**主要機能：**
- **AI動画解析** (GPT-4o-mini Vision): 任意のMP4動画を自動解析し、4DX効果のタイムラインJSONを生成
- **リアルタイム同期再生**: 動画再生と同期してデバイスを制御
- **多様な効果対応**: 振動（3モード）、光（3モード）、風、水、色（RGB）

**システム構成：**
- **動画解析エンジン** (Python + OpenCV + GPT-4o-mini): 動画からタイムラインJSON自動生成
- **Webアプリ** (React + TypeScript): 動画再生とセッション管理
- **サーバー** (FastAPI + WebSocket): リアルタイム同期処理
- **デバイスハブ** (Raspberry Pi): アクチュエーター制御
- **アクチュエーター** (Arduino + 振動モーター/香り拡散器)

### 特長

#### 1. AI自動タイムライン生成
GPT-4o-mini Visionによる映像解析で、任意のMP4動画から4DX効果タイムラインを自動生成。爆発、衝突、咆哮などのシーンを自動検出し、振動・光・風・水・色の効果を適切なタイミングで発動させるJSONを生成します。

#### 2. ミリ秒単位のリアルタイム同期
WebSocketを用いたリアルタイム通信により、動画再生と物理デバイスを±50ms以内の高精度で同期。映像に完全に連動した体感を提供します。

#### 3. 手軽なペアリング
セッションコード（4桁）を入力するだけで、Webアプリとデバイスが自動ペアリング。複雑な設定は不要で、誰でも簡単に体験を開始できます。

#### 4. コンパクト設計
手のひらサイズのデバイスで4DXシアター体験を再現。場所を取らず、自室で手軽に没入型エンターテインメントを楽しめます。

### 解決出来ること
- スマホの小さい画面では得にくい「没入感」を物理フィードバックで補完
- **どんな動画でも4DX化可能** - AIが自動解析するため、専用コンテンツ不要
- コンテンツごとに最適化された体験を提供し、作品の価値を最大化
- 大掛かりな機材が置けない環境でも、Bluetoothイヤホンのような手軽さで導入可能

### 今後の展望
- **AI精度向上**: より高精度な映像解析で、細かな演出まで検出
- **多体験対応**: 温度、水しぶき、香りなど、さらに多様な物理体験の追加
- **マルチデバイス**: 複数デバイスの同時制御による、より豊かな体験の実現
- **コンテンツ拡張**: 映画、アニメ、ゲーム、VR等、幅広いジャンルへの対応
- **クラウド化**: オンラインでの動画解析サービス提供

### 注力したこと（こだわり等）
* **AI動画解析の効率化**: GPT-4o-mini Visionのバッチ処理（15枚同時解析）により、API呼び出しを1/15に削減し、コストと処理時間を大幅に短縮
* **インテリジェント効果判定**: 爆発・衝突・咆哮などの瞬間を正確に検出し、最小継続時間制御によりチラつきを防止
* **リアルタイム同期精度**: WebSocketによる双方向通信と、継続的なタイムスタンプ送信により、動画とデバイスの同期ズレを最小化
* **ユーザビリティ**: セッションコードによる簡単ペアリング、直感的なUI設計で、技術に詳しくないユーザーでも迷わず使える体験を実現

## 開発技術
### 活用した技術
#### API・データ
* **OpenAI GPT-4o-mini (Vision API)** - マルチモーダルAIによる映像解析とシーン理解
* **WebSocket (WSS)** - リアルタイム双方向通信
* **JSON形式の同期データ** - 動画タイムスタンプとアクチュエーター制御パラメータのマッピング

#### フレームワーク・ライブラリ・モジュール
* **AI・動画処理**: OpenCV (opencv-python), requests (OpenAI API通信)
* **バックエンド**: FastAPI 0.104.1, websockets 11.0.3, Pydantic 2.5.0
* **フロントエンド**: React 18, TypeScript 5.0, Vite 4.0
* **デバイス**: Python (Raspberry Pi), Arduino (C++)

#### デバイス
* **Raspberry Pi 4** - デバイスハブとして、WebSocket通信とArduino制御を担当
* **Arduino Uno** - 振動モーター、香り拡散器などのアクチュエーターを直接制御
* **振動モーター** - 映像に合わせた触覚フィードバック（3モード: 弱い振動、強い衝撃、ドキドキ）
* **LEDライト** - 光の演出（3モード: ストロボ、閃光、照明）+ 色表現（RGB）
* **香り拡散器 (予定)** - シーンに応じた香りの演出

#### 対応効果
* **振動（vibration）**: 弱い振動（long）、強い衝撃（strong）、ドキドキ（heartbeat）
* **光（flash）**: ストロボ（strobe）、閃光（burst）、照明（steady）
* **風（wind）**: 一瞬の風（burst）、長い風（long）
* **水（water）**: 水しぶき（burst）※shot型一度きり発動
* **色（color）**: 赤（red）、緑（green）、青（blue）

### 独自技術
#### ハッカソンで開発した独自機能・技術
* **AI動画解析エンジン**: GPT-4o-mini Visionのバッチ処理（15枚同時）による効率的な映像解析と、ルールベース判定による高精度な効果タイムライン生成 ([tools/sync-generator/](tools/sync-generator/))
* **最小継続時間制御システム**: 効果のチラつき防止のため、各効果に最小継続時間を設定し、安定した体験を提供
* セッションコード方式によるシンプルなペアリングシステム ([session/manager.py](backend/app/session/manager.py))
* 動画再生タイムスタンプに基づくリアルタイム同期処理 ([sync/processor.py](backend/app/sync/processor.py))
* WebSocketによるWebアプリ・サーバー・デバイスハブの3者間通信アーキテクチャ ([websocket/manager.py](backend/app/websocket/manager.py), [hardware/device-hub/src/websocket_client.py](hardware/device-hub/src/websocket_client.py))
