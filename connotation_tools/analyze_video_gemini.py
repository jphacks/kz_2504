# -*- coding: utf-8 -*-
"""
ã€è§£æãƒ¢ãƒ¼ãƒ‰ã€‘ãƒ­ãƒ¼ã‚«ãƒ«å‹•ç”»ã‚·ãƒ¼ãƒ³è§£æï¼ˆMP4å°‚ç”¨ï¼‰- Geminiç‰ˆ
- MP4å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
- 0.5ç§’é–“éš”ã§ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ
- Google Geminiã§å„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³åŒ–
- åŠ¹æœï¼ˆå…‰/é¢¨/æ°´/è‰²/è¡æ’ƒï¼‰ã‚’JSONå½¢å¼ã§å‡ºåŠ›

ä½¿ã„æ–¹:
    python analyze_video_gemini.py video.mp4

å‡ºåŠ›: results/{video_name}_timeline.json
"""

import os, sys, cv2, json, warnings, contextlib, base64
from typing import List, Tuple, Dict
from pathlib import Path
from PIL import Image
import io
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

try:
    import google.generativeai as genai
except ImportError:
    print("âŒ google-generativeai ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„:")
    print("  pip install google-generativeai")
    sys.exit(1)

# OpenCVã¨FFmpegã®è­¦å‘Šã‚’å®Œå…¨ã«æŠ‘åˆ¶
os.environ['OPENCV_LOG_LEVEL'] = 'FATAL'
os.environ['OPENCV_FFMPEG_CAPTURE_OPTIONS'] = 'loglevel;fatal'
os.environ['OPENCV_VIDEOIO_DEBUG'] = '0'
warnings.filterwarnings('ignore')
cv2.setLogLevel(0)

@contextlib.contextmanager
def suppress_stderr():
    """æ¨™æº–ã‚¨ãƒ©ãƒ¼å‡ºåŠ›ã‚’æŠ‘åˆ¶"""
    stderr_fd = sys.stderr.fileno()
    with open(os.devnull, 'w') as devnull:
        old_stderr = os.dup(stderr_fd)
        os.dup2(devnull.fileno(), stderr_fd)
        try:
            yield
        finally:
            os.dup2(old_stderr, stderr_fd)
            os.close(old_stderr)

# ===== è¨­å®š =====
# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«ãƒ‘ã‚¹ã‚’è§£æ±º
SCRIPT_DIR = Path(__file__).parent.absolute()
VIDEOS_DIR = str(SCRIPT_DIR / "videos")            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå‹•ç”»ã‚’é…ç½®ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
RESULTS_DIR = str(SCRIPT_DIR / "results")          # JSONå‡ºåŠ›å…ˆ
SAMPLE_INTERVAL = 0.25           # 0.25ç§’ã”ã¨ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ4DX@HOMEä»•æ§˜ï¼‰
BATCH_SIZE = 100                 # ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆ4DX@HOMEä»•æ§˜ã€æœ€å¤§480æšã¾ã§å¯¾å¿œå¯èƒ½ï¼‰
MODEL_NAME = "gemini-2.5-pro"    # Geminiãƒ¢ãƒ‡ãƒ«åï¼ˆ4DX@HOMEä»•æ§˜: gemini-2.5-proå›ºå®šï¼‰
TARGET_WIDTH = 640               # APIè² è·è»½æ¸›ã®ç¸®å°å¹…
PROMPT_NAME = "4dx_home"        # ä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåï¼ˆ4DX@HOMEå°‚ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰
MAX_CONCURRENT_REQUESTS = 10     # åŒæ™‚å®Ÿè¡Œæ•°ã®ä¸Šé™ï¼ˆGemini APIã®ä¸¦åˆ—ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ï¼‰

# ç›´æ¥æ›¸ããŸã„å ´åˆã¯ã“ã“ã«ã‚­ãƒ¼æ–‡å­—åˆ—ã‚’å…¥ã‚Œã‚‹ï¼ˆä¾‹: "AIza..."ï¼‰ã€‚ç©ºæ–‡å­—ãªã‚‰ç„¡åŠ¹ã€‚
HARD_CODED_GEMINI_API_KEY = "/"
# å„ªå…ˆé †: ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ > ç’°å¢ƒå¤‰æ•°
GEMINI_API_KEY = HARD_CODED_GEMINI_API_KEY or os.getenv("GEMINI_API_KEY")

# Gemini APIã®åˆæœŸåŒ–
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    print("âš ï¸  GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("   ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã‚’è¨­å®šã™ã‚‹ã‹ã€")
    print("   ã‚³ãƒ¼ãƒ‰å†…ã® HARD_CODED_GEMINI_API_KEY ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")

# ===== åŠ¹æœãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆ4DX@HOMEä»•æ§˜ï¼‰=====
EFFECT_DOMAIN = {
    "flash": ["steady", "slow_blink", "fast_blink"],  # å…‰: ç‚¹ç¯/é…ã„ç‚¹æ»…/æ—©ã„ç‚¹æ»…
    "wind": ["on"],                                    # é¢¨: ã‚ªãƒ³/ã‚ªãƒ•
    "water": ["on"],                                   # æ°´ã—ã¶ã: ã‚ªãƒ³/ã‚ªãƒ•
    "color": ["red", "green", "blue", "yellow", "cyan", "purple"],  # è‰²: èµ¤/ç·‘/é’/é»„è‰²/ã‚·ã‚¢ãƒ³/ç´«
    "vibration": ["up_strong", "up_mid_strong", "up_mid_weak", "up_weak",  # æŒ¯å‹•: ä¸Šã®å¼·/ä¸­å¼·/ä¸­å¼±/å¼±ï¼ˆèƒŒä¸­ï¼‰
                  "down_strong", "down_mid_strong", "down_mid_weak", "down_weak",  # ä¸‹ã®å¼·/ä¸­å¼·/ä¸­å¼±/å¼±ï¼ˆãŠã—ã‚Šï¼‰
                  "up_down_strong", "up_down_mid_strong", "up_down_mid_weak", "up_down_weak",  # ä¸Šï¼†ä¸‹åŒæ™‚ï¼ˆèƒŒä¸­ï¼†ãŠã—ã‚Šã€ã‹ãªã‚Šå¼·ã„ï¼‰
                  "heartbeat"],  # ãƒ‰ã‚­ãƒ‰ã‚­
}

# ===== åŠ¹æœã®æœ€å°ç¶™ç¶šæ™‚é–“ï¼ˆç§’ï¼‰- 4DX@HOMEä»•æ§˜ =====
MIN_DURATION = {
    # æŒ¯å‹•: 0.5ç§’ä»¥ä¸Šï¼ˆæ™‚ã«ã¯0.25ç§’ã§ã‚‚å¯ï¼‰
    "vibration:up_strong": 0.5,
    "vibration:up_mid_strong": 0.5,
    "vibration:up_mid_weak": 0.5,
    "vibration:up_weak": 0.5,
    "vibration:down_strong": 0.5,
    "vibration:down_mid_strong": 0.5,
    "vibration:down_mid_weak": 0.5,
    "vibration:down_weak": 0.5,
    "vibration:up_down_strong": 0.5,      # ä¸Šï¼†ä¸‹åŒæ™‚: å¼·ï¼ˆã‹ãªã‚Šå¼·ã„ï¼‰
    "vibration:up_down_mid_strong": 0.5,   # ä¸Šï¼†ä¸‹åŒæ™‚: ä¸­å¼·ï¼ˆã‹ãªã‚Šå¼·ã„ï¼‰
    "vibration:up_down_mid_weak": 0.5,     # ä¸Šï¼†ä¸‹åŒæ™‚: ä¸­å¼±ï¼ˆã‹ãªã‚Šå¼·ã„ï¼‰
    "vibration:up_down_weak": 0.5,         # ä¸Šï¼†ä¸‹åŒæ™‚: å¼±ï¼ˆã‹ãªã‚Šå¼·ã„ï¼‰
    "vibration:heartbeat": 0.5,  # ãƒ‰ã‚­ãƒ‰ã‚­ã‚‚0.5ç§’ä»¥ä¸Š
    
    # å…‰: 2-3ç§’ç¨‹åº¦ã‚†ã£ãã‚Šå¤‰åŒ–ï¼ˆæ˜ åƒã«åˆã‚ã›ã¦ï¼‰
    "flash:steady": 2.0,         # ç‚¹ç¯: 2ç§’ä»¥ä¸Š
    "flash:slow_blink": 2.0,     # é…ã„ç‚¹æ»…: 2ç§’ä»¥ä¸Š
    "flash:fast_blink": 1.0,     # æ—©ã„ç‚¹æ»…: 1ç§’ä»¥ä¸Š
    
    # è‰²: 2-3ç§’ç¨‹åº¦ã‚†ã£ãã‚Šå¤‰åŒ–
    "color:red": 2.0,
    "color:green": 2.0,
    "color:blue": 2.0,
    "color:yellow": 2.0,
    "color:cyan": 2.0,
    "color:purple": 2.0,
    
    # é¢¨: ç¶™ç¶šçš„ã«
    "wind:on": 1.0,
    
    # æ°´ã—ã¶ã: ç¬é–“çš„
    "water:on": 0.5,
}

# ===== ãƒ«ãƒ¼ãƒ«: ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³â†’åŠ¹æœï¼ˆ4DX@HOMEä»•æ§˜ - æ–°ãƒ«ãƒ¼ãƒ«ï¼‰=====
# æ³¨æ„: ã“ã®ãƒ«ãƒ¼ãƒ«ã¯å‚è€ƒç”¨ã€‚å®Ÿéš›ã®åˆ¤å®šã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§AIãŒè¡Œã†
RULES = [
    # === æŒ¯å‹•ã‚’åœæ­¢ã™ã‚‹æ¡ä»¶ï¼ˆæœ€å„ªå…ˆã§ãƒã‚§ãƒƒã‚¯ï¼‰===
    # ã“ã‚Œã‚‰ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯æŒ¯å‹•ã‚’å‡ºã•ãªã„
    # ï¼ˆdecide_effectsé–¢æ•°å†…ã§åˆ¥é€”å‡¦ç†ï¼‰
    
    # === å¼·ã„è¡æ’ƒï¼ˆç¬é–“çš„ï¼‰===
    # è¡çªã®ç¬é–“
    (["è¡çªã™ã‚‹ç¬é–“","è¡çªã®ç¬é–“","ã¶ã¤ã‹ã‚‹ç¬é–“","æ¿€çª","moment of collision","crash into","smash"],
     [("vibration","strong")]),
    
    # çˆ†ç™ºã®ç¬é–“
    (["çˆ†ç™ºã™ã‚‹ç¬é–“","çˆ†ç™ºã®ç¬é–“","çˆ†ç™ºãŒç™ºç”Ÿ","çˆ†ç™ºã—ãŸ","explosion occurs","explodes","detonates"],
     [("vibration","strong"), ("flash","burst"), ("color","red")]),
    
    # ç€åœ°ã®ç¬é–“
    (["ç€åœ°ã™ã‚‹ç¬é–“","ç€åœ°ã®ç¬é–“","åœ°é¢ã«å©ãã¤ã‘","lands","touches down","hits ground"],
     [("vibration","strong")]),
    
    # æ”»æ’ƒã®ç¬é–“
    (["æ”»æ’ƒã®ç¬é–“","æ‰“æ’ƒã®ç¬é–“","æ®´ã‚‹ç¬é–“","è¹´ã‚‹ç¬é–“","hits","strikes","punches","kicks"],
     [("vibration","strong")]),
    
    # === å¼±ã„æŒ¯å‹•ï¼ˆç¶™ç¶šçš„ï¼‰===
    # ä¹—ã‚Šç‰©ã«ä¹—ã£ã¦ã„ã‚‹é–“ï¼ˆæœ€å„ªå…ˆï¼‰
    (["ä¹—ã£ã¦ã„ã‚‹","ä¹—è»Š","æˆ¦é—˜æ©Ÿ","è»Šå†…","èˆ¹","é£›è¡Œæ©Ÿ","ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ","é‹è»¢å¸­","æ“ç¸¦",
      "riding","on board","in the","piloting","cockpit","driving","vehicle"],
     [("vibration","long")]),
    
    # ç§»å‹•ä¸­ãƒ»é£›è¡Œä¸­
    (["é£›è¡Œä¸­","é£›ã‚“ã§ã„ã‚‹","ç§»å‹•ä¸­","èµ°è¡Œä¸­","é‹è»¢ä¸­","æ­©ã„ã¦ã„ã‚‹","èµ°ã£ã¦ã„ã‚‹","é€²ã‚“ã§ã„ã‚‹",
      "flying","moving","driving","running","walking","advancing","traveling"],
     [("vibration","long")]),
    
    # æˆ¦é—˜ãƒ»ãƒãƒˆãƒ«ä¸­ï¼ˆæ¿€ã—ã„å‹•ãï¼‰
    (["æˆ¦é—˜ä¸­","ãƒãƒˆãƒ«ä¸­","æˆ¦ã£ã¦ã„ã‚‹","æš´ã‚Œã¦ã„ã‚‹","æ¿€ã—ãå‹•ã„ã¦ã„ã‚‹","æ ¼é—˜",
      "fighting","battling","combat","struggling","intense"],
     [("vibration","long")]),
    
    # === ç”Ÿç‰©ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ ===
    # å’†å“®ãƒ»å ãˆã‚‹ãƒ»å«ã³ï¼ˆè¡æ’ƒæ³¢ + å”¾ãƒ»æ¯ã®é£›æ²«ï¼‰- æœ€å„ªå…ˆã§æ¤œå‡º
    (["å’†å“®","å’†å“®ã—ã¦ã„ã‚‹","å ãˆã‚‹","å ãˆã¦ã„ã‚‹","å ãˆãŸ","å«ã¶","å«ã‚“ã§ã„ã‚‹","çµ¶å«","æ€’é³´ã‚‹","å”¸ã‚‹",
      "roar","roaring","roars","howl","howling","scream","screaming","shout","shouting","yell","yelling","growl","snarl"],
     [("vibration","strong"), ("water","burst"), ("wind","burst")]),
    
    # å‘¼å¸ãƒ»æºœæ¯ï¼ˆé¢¨ãƒ»æ¯ï¼‰
    (["å‘¼å¸","æºœæ¯","æ¯","åã","å¸ã†","breath","sigh","exhale","inhale"],
     [("wind","burst")]),
    
    # === å…‰ã®åŠ¹æœ ===
    # é›·ï¼ˆãƒã‚«ãƒã‚«ï¼‰
    (["é›·","ç¨²å¦»","é›·é³´","lightning","thunder"],
     [("flash","strobe")]),
    
    # çˆ†ç™ºï¼ˆå…‰ + æŒ¯å‹• + ç‚ã®è‰²ï¼‰
    (["çˆ†ç™º","é–ƒå…‰","çˆ†ç ´","ç‚¸è£‚","explosion","explode","blast","detonation"],
     [("flash","burst"), ("vibration","strong"), ("color","red")]),
    
    # ç«èŠ±ï¼ˆå…‰ + æŒ¯å‹•ï¼‰
    (["ç«èŠ±","ã‚¹ãƒ‘ãƒ¼ã‚¯","ç«ã®ç²‰","spark","sparks","sparking"],
     [("flash","burst"), ("vibration","strong")]),
    
    # ç‚ãŒè¦‹ãˆã‚‹ï¼ˆå…‰ + æŒ¯å‹• + èµ¤è‰²ï¼‰
    (["ç‚ãŒè¦‹ãˆã‚‹","ç‚ãŒä¸ŠãŒã‚‹","ç‡ƒãˆã¦ã„ã‚‹","ç‚","flames","fire","burning"],
     [("flash","steady"), ("vibration","long"), ("color","red")]),
    
    # ç…§æ˜ãƒ»å¤•æ—¥ï¼ˆç¶™ç¶šçš„ãªå…‰ï¼‰
    (["ç…§ã‚‰ã™","ãƒ©ã‚¤ãƒˆ","å…‰ã‚‹","å¤•æ—¥","ç…§æ˜","æ—¥å·®ã—","light","illuminate","shine","sunset","sunlight"],
     [("flash","steady")]),
    
    # === é¢¨ ===
    # è¡æ’ƒæ³¢ãƒ»çˆ†é¢¨ï¼ˆä¸€ç¬ï¼‰
    (["è¡æ’ƒæ³¢","çªé¢¨","çˆ†é¢¨","blast","shock wave","gust"],
     [("wind","burst")]),
    
    # ç¶™ç¶šçš„ãªé¢¨
    (["é¢¨","ç ‚åŸƒ","ç…™","ç–¾èµ°","ã‚¹ãƒ”ãƒ¼ãƒ‰","wind","dust","smoke","speed","fast"],
     [("wind","long")]),
    
    # === æ°´ãƒ»é£›æ²« ===
    # å”¾ãƒ»æ¯ã®é£›æ²«
    (["å”¾","ã¤ã°","é£›æ²«","ã‚ˆã ã‚Œ","saliva","spit","drool"],
     [("water","burst")]),
    
    # æ°´ã—ã¶ããƒ»æ³¢
    (["æ°´","æ°´ã—ã¶ã","æ³¢","å™´å°„","ã‚¹ãƒ—ãƒ¬ãƒ¼","æ¿¡ã‚Œã‚‹","é›¨","æ±—","blood","water","splash","spray","wave","wet","rain"],
     [("water","burst")]),
    
    # === è‰² ===
    (["èµ¤","ç‚","ç«","ã‚ªãƒ¬ãƒ³ã‚¸","è¡€","red","flame","fire","orange","blood"],
     [("color","red")]),
    (["ç·‘","æ£®","è‰åŸ","è‡ªç„¶","green","forest","grass","nature"],
     [("color","green")]),
    (["é’","ç©º","æµ·","æ°´","blue","sky","ocean","water"],
     [("color","blue")]),
    
    # === ãã®ä»–ã®æŒ¯å‹• ===
    # ç·Šå¼µæ„Ÿï¼ˆãƒ‰ã‚­ãƒ‰ã‚­ï¼‰
    (["ç·Šå¼µ","ãƒ‰ã‚­ãƒ‰ã‚­","å¿ƒæ‹","ä¸å®‰","å±é™º","tense","nervous","anxious","heartbeat","danger"],
     [("vibration","heartbeat")]),
]

# ===== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =====
def resize_and_b64(frame_bgr, target_w=TARGET_WIDTH):
    """ç”»åƒã‚’ç¸®å°ã—ã¦PNGâ†’Base64åŒ–"""
    h, w = frame_bgr.shape[:2]
    if w > target_w:
        scale = target_w / float(w)
        frame_bgr = cv2.resize(frame_bgr, (target_w, int(h*scale)))
    ok, buf = cv2.imencode(".png", frame_bgr)
    if not ok:
        raise RuntimeError("PNGã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å¤±æ•—")
    return base64.b64encode(buf.tobytes()).decode("utf-8")

def base64_to_pil_image(base64_str: str) -> Image.Image:
    """Base64æ–‡å­—åˆ—ã‚’PIL Imageã«å¤‰æ›"""
    image_data = base64.b64decode(base64_str)
    return Image.open(io.BytesIO(image_data))

def get_video_info(video_path: str) -> Tuple[float, int, float]:
    """å‹•ç”»æƒ…å ±ã‚’å–å¾—"""
    with suppress_stderr():
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise RuntimeError(f"å‹•ç”»ã‚’é–‹ã‘ãªã„: {video_path}")
        fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0.0
        cap.release()
    return fps, total_frames, duration

def format_actions_for_prompt(effs: List[Tuple[str,str]]) -> str:
    if not effs:
        return "(none)"
    return ", ".join([f"{e}:{m}" for e, m in effs])

def format_delta_for_prompt(delta_events: List[Dict]) -> str:
    if not delta_events:
        return "(none)"
    parts = []
    for ev in delta_events:
        if ev.get("action") in ("start", "stop"):
            parts.append(f"{ev['action']} {ev['effect']}:{ev['mode']}")
    return ", ".join(parts) if parts else "(none)"

def list_available_models():
    """åˆ©ç”¨å¯èƒ½ãªGeminiãƒ¢ãƒ‡ãƒ«ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—"""
    if not GEMINI_API_KEY:
        print("âš ï¸  APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—ã§ãã¾ã›ã‚“ã€‚")
        return []
    
    try:
        models = genai.list_models()
        available = []
        for m in models:
            # generateContentãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
            if hasattr(m, 'supported_generation_methods') and 'generateContent' in m.supported_generation_methods:
                model_name = m.name.replace('models/', '')
                available.append(model_name)
        return available
    except Exception as e:
        print(f"âš ï¸  ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return []

def caption_batch_vlm(frames_data: List[Dict], model_name: str = None, prompt_name: str = None) -> Tuple[List[str], List[Dict]]:
    """ãƒãƒƒãƒå‡¦ç†: è¤‡æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä¸€åº¦ã«è§£æï¼ˆGeminiç‰ˆï¼‰"""
    if not GEMINI_API_KEY:
        raise RuntimeError("GEMINI_API_KEY æœªè¨­å®šã€‚ç’°å¢ƒå¤‰æ•°ã«è¨­å®šã™ã‚‹ã‹ã€ã‚³ãƒ¼ãƒ‰å†…ã®HARD_CODED_GEMINI_API_KEYã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    try:
        from prompts import get_prompt
    except ImportError:
        raise RuntimeError("prompts.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
    
    # ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•é¸æŠ
    if model_name is None:
        model_name = get_available_model()
    
    try:
        model = genai.GenerativeModel(model_name)
    except Exception as e:
        # ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º
        error_msg = str(e)
        if "not found" in error_msg.lower() or "404" in error_msg:
            print(f"\nâŒ ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            print("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªä¸­...")
            available = list_available_models()
            if available:
                print("âœ… åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:")
                for m in available:
                    print(f"   - {m}")
                print(f"\nğŸ’¡ ã‚³ãƒ¼ãƒ‰å†…ã® MODEL_NAME ã‚’ä¸Šè¨˜ã®ã„ãšã‚Œã‹ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚")
            else:
                print("âš ï¸  åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        raise RuntimeError(f"Geminiãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å–å¾—
    prompt_text = get_prompt(prompt_name, num_frames=len(frames_data))
    
    # ç”»åƒã‚’PIL Imageã«å¤‰æ›
    images = []
    for frame_data in frames_data:
        pil_image = base64_to_pil_image(frame_data['b64_image'])
        images.append(pil_image)
    
    # Gemini APIã«é€ä¿¡ï¼ˆç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ„ã¿åˆã‚ã›ï¼‰
    content = [prompt_text] + images
    
    try:
        # ç”Ÿæˆè¨­å®š
        generation_config = {
            "temperature": 0.2,
            "max_output_tokens": 2048 * len(frames_data),  # 4DX@HOMEä»•æ§˜: åŠ¹æœæƒ…å ±ã‚‚å«ã‚€ãŸã‚å¢—ã‚„ã™
            "response_mime_type": "application/json",
        }
        
        response = model.generate_content(
            content,
            generation_config=generation_config
        )
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        response_text = response.text
        
        # JSONã‚’è§£æ
        try:
            obj = json.loads(response_text)
            
            # 4DX@HOMEä»•æ§˜: frameså½¢å¼ã‹captionså½¢å¼ã‹ã‚’åˆ¤å®š
            if "frames" in obj:
                # æ–°ã—ã„å½¢å¼ï¼ˆ4DX@HOMEï¼‰
                frames_data_result = obj.get("frames", [])
                captions = []
                effects_list = []
                
                for frame_result in frames_data_result:
                    captions.append(frame_result.get("caption", "ã‚·ãƒ¼ãƒ³ãŒç¶šã"))
                    effects_list.append(frame_result.get("effects", {}))
                
                # ä¸è¶³åˆ†ã‚’è£œå®Œ
                while len(captions) < len(frames_data):
                    captions.append(captions[-1] if captions else "ã‚·ãƒ¼ãƒ³ãŒç¶šã")
                    effects_list.append({})
                
                return captions, effects_list
            else:
                # æ—§å½¢å¼ï¼ˆcaptionsã®ã¿ï¼‰
                captions = obj.get("captions", [])
                if not isinstance(captions, list):
                    raise ValueError("captions ãŒé…åˆ—ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
                
                if len(captions) != len(frames_data):
                    if len(captions) > len(frames_data):
                        print(f"      âš ï¸  ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æ•°ãŒå¤šã„ï¼ˆæœŸå¾…={len(frames_data)}, å–å¾—={len(captions)}ï¼‰-> æœ€åˆã®{len(frames_data)}å€‹ã‚’ä½¿ç”¨")
                        captions = captions[:len(frames_data)]
                    else:
                        print(f"      âš ï¸  ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³æ•°ãŒå°‘ãªã„ï¼ˆæœŸå¾…={len(frames_data)}, å–å¾—={len(captions)}ï¼‰-> èª¿æ•´ä¸­...")
                        combined = " ".join(captions)
                        captions = [combined] + captions[1:] if len(captions) > 0 else []
                        while len(captions) < len(frames_data):
                            captions.append(captions[-1] if captions else "ã‚·ãƒ¼ãƒ³ãŒç¶šã")
                
                # æ—§å½¢å¼ã®å ´åˆã¯åŠ¹æœãªã—
                return captions, [{}] * len(captions)
                
        except json.JSONDecodeError as e:
            # JSONè§£æã«å¤±æ•—ã—ãŸå ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥æŠ½å‡ºã‚’è©¦ã¿ã‚‹
            print(f"      âš ï¸  JSONè§£æå¤±æ•—ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æŠ½å‡ºã‚’è©¦ã¿ã¾ã™...")
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡Œã”ã¨ã«åˆ†å‰²ã—ã¦ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¨ã—ã¦ä½¿ç”¨
            lines = [line.strip() for line in response_text.split('\n') if line.strip()]
            if len(lines) >= len(frames_data):
                captions = lines[:len(frames_data)]
            else:
                # ä¸è¶³åˆ†ã‚’è£œå®Œ
                while len(lines) < len(frames_data):
                    lines.append(lines[-1] if lines else "ã‚·ãƒ¼ãƒ³ãŒç¶šã")
                captions = lines
            
            return captions, [{}] * len(captions)
                
    except Exception as e:
        raise RuntimeError(f"Gemini APIå‘¼ã³å‡ºã—å¤±æ•—: {e}")

def get_effect_display_name(effect: str, mode: str) -> str:
    """åŠ¹æœã®æ—¥æœ¬èªè¡¨ç¤ºåã‚’å–å¾—ï¼ˆ4DX@HOMEä»•æ§˜ï¼‰"""
    effect_names = {
        # å…‰
        "flash:steady": "ğŸ’¡ç‚¹ç¯",
        "flash:slow_blink": "ğŸ’¡é…ã„ç‚¹æ»…",
        "flash:fast_blink": "âš¡æ—©ã„ç‚¹æ»…",
        # è‰²
        "color:red": "ğŸ”´èµ¤",
        "color:green": "ğŸŸ¢ç·‘",
        "color:blue": "ğŸ”µé’",
        "color:yellow": "ğŸŸ¡é»„è‰²",
        "color:cyan": "ğŸ”·ã‚·ã‚¢ãƒ³",
        "color:purple": "ğŸŸ£ç´«",
        # æŒ¯å‹•
        "vibration:up_strong": "ğŸ“³ä¸Š:å¼·",
        "vibration:up_mid_strong": "ğŸ“³ä¸Š:ä¸­å¼·",
        "vibration:up_mid_weak": "ğŸ“³ä¸Š:ä¸­å¼±",
        "vibration:up_weak": "ğŸ“³ä¸Š:å¼±",
        "vibration:down_strong": "ğŸ“³ä¸‹:å¼·",
        "vibration:down_mid_strong": "ğŸ“³ä¸‹:ä¸­å¼·",
        "vibration:down_mid_weak": "ğŸ“³ä¸‹:ä¸­å¼±",
        "vibration:down_weak": "ğŸ“³ä¸‹:å¼±",
        "vibration:heartbeat": "ğŸ’“ãƒ‰ã‚­ãƒ‰ã‚­",
        # é¢¨ãƒ»æ°´
        "wind:on": "ğŸ’¨é¢¨",
        "water:on": "ğŸ’¦æ°´ã—ã¶ã",
    }
    return effect_names.get(f"{effect}:{mode}", f"{effect}:{mode}")

def decide_effects_from_json(effects_dict: Dict) -> List[Tuple[str,str]]:
    """JSONå½¢å¼ã®åŠ¹æœæƒ…å ±ã‹ã‚‰åŠ¹æœãƒªã‚¹ãƒˆã‚’ç”Ÿæˆï¼ˆ4DX@HOMEä»•æ§˜ï¼‰"""
    chosen: List[Tuple[str,str]] = []
    
    # å„åŠ¹æœã‚¿ã‚¤ãƒ—ã‚’ãƒã‚§ãƒƒã‚¯
    for effect_type in ["flash", "color", "vibration", "water", "wind"]:
        mode = effects_dict.get(effect_type)
        if mode and mode != "null" and mode is not None:
            # æ°´ã¨é¢¨ã¯å†…éƒ¨ã§ "on" ã¨ã—ã¦æ‰±ã†ï¼ˆå‡ºåŠ›æ™‚ã«æ—¢å­˜JSONå½¢å¼ã«å¤‰æ›ï¼‰
            if effect_type == "water" and mode == "on":
                chosen.append((effect_type, "on"))  # å†…éƒ¨å‡¦ç†ç”¨
            elif effect_type == "wind" and mode == "on":
                chosen.append((effect_type, "on"))  # å†…éƒ¨å‡¦ç†ç”¨ã€å‡ºåŠ›æ™‚ã« "burst" ã«å¤‰æ›
            else:
                chosen.append((effect_type, mode))
    
    return chosen

def decide_effects(caption: str, effects_dict: Dict = None) -> List[Tuple[str,str]]:
    """ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¾ãŸã¯JSONåŠ¹æœæƒ…å ±ã‹ã‚‰åŠ¹æœé›†åˆã‚’æ±ºå®šï¼ˆ4DX@HOMEä»•æ§˜ï¼‰"""
    # 4DX@HOMEä»•æ§˜: JSONåŠ¹æœæƒ…å ±ãŒå„ªå…ˆ
    if effects_dict:
        return decide_effects_from_json(effects_dict)
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ—§æ–¹å¼ï¼ˆã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰åˆ¤å®šï¼‰
    cap_l = caption.lower()
    chosen: List[Tuple[str,str]] = []
    
    # === æŒ¯å‹•ã‚’æ­¢ã‚ã‚‹æ¡ä»¶ï¼ˆå³æ ¼ã«åˆ¤å®šï¼‰===
    # å®Œå…¨ã«é™æ­¢ã—ã¦ã„ã‚‹å ´åˆã®ã¿
    is_static = any(kw in caption or kw in cap_l for kw in 
                    ["å®Œå…¨ã«é™æ­¢", "å…¨ãå‹•ã„ã¦ã„ãªã„", "é™æ­¢ã—ã¦ã„ã‚‹",
                     "completely still", "totally motionless"])
    
    # é™ã‚Šã¦ã„ã¦ ã‹ã¤ é™æ­¢ã—ã¦ã„ã‚‹ï¼ˆä¸¡æ–¹å¿…è¦ï¼‰
    is_dismounted_and_static = (
        any(kw in caption or kw in cap_l for kw in ["é™ã‚Šã¦ã„ã‚‹", "é™ã‚ŠãŸ", "dismounted"]) and
        is_static
    )
    
    # === æŒ¯å‹•ã‚’å‡ºã™æ¡ä»¶ ===
    # ã‚¸ãƒ£ãƒ³ãƒ—ä¸­ãƒ»ç©ºä¸­ã®åˆ¤å®šï¼ˆä¹—ã‚Šç‰©ãªã—ã§ç©ºä¸­ã«ã„ã‚‹å ´åˆï¼‰
    is_airborne = any(kw in caption or kw in cap_l for kw in 
                      ["ã‚¸ãƒ£ãƒ³ãƒ—", "ç©ºä¸­", "é£›ã¶", "æµ®ã‹ã¶", "å®™", "jump", "airborne", "flying", "mid-air"])
    
    # ä¹—ã‚Šç‰©ã«ä¹—ã£ã¦ã„ã‚‹ã‹ã®åˆ¤å®šï¼ˆã‚ˆã‚Šè©³ç´°ã«ï¼‰
    is_riding = any(kw in caption or kw in cap_l for kw in 
                    ["ä¹—ã£ã¦ã„ã‚‹", "ä¹—è»Š", "æˆ¦é—˜æ©Ÿã«", "è»Šã«", "èˆ¹ã«", "é£›è¡Œæ©Ÿã«", "é¦¬ã«",
                     "riding", "on board", "in the", "in vehicle", "piloting", "driving"])
    
    # ãƒ«ãƒ¼ãƒ«ãƒãƒƒãƒãƒ³ã‚°
    for kws, effs in RULES:
        if any((kw in caption) or (kw.lower() in cap_l) for kw in kws):
            chosen.extend(effs)
    
    # === æŒ¯å‹•ã®é™¤å¤–ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆç·©ãï¼‰ ===
    # 1. å®Œå…¨ã«é™æ­¢ã—ã¦ã„ã‚‹å ´åˆã®ã¿å¼±ã„æŒ¯å‹•ã‚’é™¤å¤–
    if is_dismounted_and_static:
        chosen = [(e, m) for e, m in chosen if not (e == "vibration" and m == "long")]
    
    # 2. ç©ºä¸­ã‹ã¤ä¹—ã‚Šç‰©ã«ä¹—ã£ã¦ã„ãªã„å ´åˆã®ã¿ã€ç¶™ç¶šçš„ãªæŒ¯å‹•ã‚’é™¤å¤–
    # ï¼ˆä¹—ã‚Šç‰©ã«ä¹—ã£ã¦ã„ã‚Œã°ç©ºä¸­ã§ã‚‚æŒ¯å‹•ã‚ã‚Šï¼‰
    if is_airborne and not is_riding:
        chosen = [(e, m) for e, m in chosen if not (e == "vibration" and m in ["long", "heartbeat"])]
    
    # é‡è¤‡é™¤å»
    seen, uniq = set(), []
    for e in chosen:
        if e not in seen:
            seen.add(e); uniq.append(e)
    return uniq

def diff_events(prev_eff: List[Tuple[str,str]], curr_eff: List[Tuple[str,str]], t: float, 
                effect_start_times: Dict[Tuple[str,str], float]) -> Tuple[List[Dict], List[Tuple[str,str]]]:
    """
    å‰å›ã¨ã®å·®åˆ†ã§ start/stop ã‚’ç”Ÿæˆï¼ˆ4DX@HOMEä»•æ§˜ï¼‰
    æœ€å°ç¶™ç¶šæ™‚é–“ã‚’è€ƒæ…®ã—ã¦ã€çŸ­ã™ãã‚‹åŠ¹æœã¯ç¶™ç¶šã•ã›ã‚‹
    æ°´ã¯ shot ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€é¢¨ã¯ start/stop ã§åˆ¶å¾¡ï¼ˆæ—¢å­˜JSONå½¢å¼ã«åˆã‚ã›ã‚‹ï¼‰
    """
    events = []
    ps, cs = set(prev_eff), set(curr_eff)
    
    # æ°´ã®åŠ¹æœã‚’ç‰¹åˆ¥å‡¦ç†ï¼ˆä¸€åº¦ãã‚Šã®ç™ºå°„ - æ—¢å­˜JSONå½¢å¼ã«åˆã‚ã›ã‚‹ï¼‰
    water_effects = {eff for eff in (cs - ps) if eff[0] == "water"}
    for eff in water_effects:
        # æ°´ã¯ "shot" ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã§ä¸€åº¦ã ã‘ç™ºç«ï¼ˆæ—¢å­˜JSONå½¢å¼: "burst" ãƒ¢ãƒ¼ãƒ‰ï¼‰
        events.append({"t": round(t,3), "action":"shot", "effect":eff[0], "mode":"burst"})
        # csã‹ã‚‰å‰Šé™¤ï¼ˆstart/stopã®å¯¾è±¡å¤–ï¼‰
        cs.discard(eff)
    
    # æ°´ä»¥å¤–ã®åŠ¹æœã‚’å‡¦ç†
    # åœæ­¢å€™è£œã®åŠ¹æœ
    for eff in (ps - cs):
        if eff[0] == "water":
            continue  # æ°´ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿
        
        effect_key = f"{eff[0]}:{eff[1]}"
        start_time = effect_start_times.get(eff, 0.0)
        duration = t - start_time
        min_duration = MIN_DURATION.get(effect_key, 0.5)
        
        # åŒã˜effect typeã®åˆ¥modeãŒæ¥ãŸå ´åˆã®åˆ¤å®š
        same_type_different_mode = [e for e in cs if e[0] == eff[0] and e != eff]
        
        # æŒ¯å‹•ã¯è¤‡æ•°ã®ãƒ¢ãƒ¼ãƒ‰ã‚’åŒæ™‚ã«æŒã¦ã‚‹
        # å…‰ãƒ»è‰²ã¯ä¸Šæ›¸ãï¼ˆåŒã˜ã‚¿ã‚¤ãƒ—ã®åˆ¥ãƒ¢ãƒ¼ãƒ‰ãŒæ¥ãŸã‚‰åˆ‡ã‚Šæ›¿ãˆï¼‰
        # é¢¨ã¯å˜ä¸€ï¼ˆon/offã€æ—¢å­˜JSONå½¢å¼ã§ã¯ "burst" ãƒ¢ãƒ¼ãƒ‰ï¼‰
        can_coexist = (eff[0] == "vibration")
        
        # ä¸Šæ›¸ãã•ã‚ŒãŸã‹ã©ã†ã‹
        is_overwritten = len(same_type_different_mode) > 0 and not can_coexist
        
        # æœ€å°ç¶™ç¶šæ™‚é–“ã«é”ã—ã¦ã„ãªã„ ã‹ã¤ ä¸Šæ›¸ãã•ã‚Œã¦ã„ãªã„å ´åˆã¯ç¶™ç¶š
        if duration < min_duration and not is_overwritten:
            # ç¶™ç¶šã•ã›ã‚‹
            cs.add(eff)
        else:
            # åœæ­¢ï¼ˆé¢¨ã®å ´åˆã¯ "burst" ãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›ï¼‰
            mode = eff[1]
            if eff[0] == "wind" and mode == "on":
                mode = "burst"  # æ—¢å­˜JSONå½¢å¼ã«åˆã‚ã›ã‚‹
            events.append({"t": round(t,3), "action":"stop", "effect":eff[0], "mode":mode})
            # é–‹å§‹æ™‚åˆ»ã‚’å‰Šé™¤
            if eff in effect_start_times:
                del effect_start_times[eff]
    
    # æ–°è¦é–‹å§‹ã®åŠ¹æœï¼ˆæ°´ä»¥å¤–ï¼‰
    for eff in (cs - ps):
        if eff[0] == "water":
            continue  # æ°´ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿
        
        # é¢¨ã®å ´åˆã¯ "on" ã‚’ "burst" ã«å¤‰æ›ï¼ˆæ—¢å­˜JSONå½¢å¼ã«åˆã‚ã›ã‚‹ï¼‰
        mode = eff[1]
        if eff[0] == "wind" and mode == "on":
            mode = "burst"
        
        events.append({"t": round(t,3), "action":"start","effect":eff[0], "mode":mode})
        effect_start_times[eff] = t  # é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²
    
    return events, list(cs)

def get_available_model():
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã—ã€è¨­å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯æœ€åˆã®åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™"""
    # 4DX@HOMEä»•æ§˜: gemini-2.5-proå›ºå®š
    if MODEL_NAME == "gemini-2.5-pro":
        return MODEL_NAME
    
    available_models = list_available_models()
    if available_models:
        # è¨­å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆ
        if MODEL_NAME in available_models:
            return MODEL_NAME
        # è¨­å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ä¸å¯ã®å ´åˆã€æœ€åˆã®åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
        else:
            print(f"âš ï¸  è¨­å®šã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
            print(f"   â†’ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ« '{available_models[0]}' ã‚’è‡ªå‹•çš„ã«ä½¿ç”¨ã—ã¾ã™ã€‚")
            return available_models[0]
    else:
        # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ãŒå–å¾—ã§ããªã„å ´åˆã€è¨­å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãã®ã¾ã¾ä½¿ç”¨
        print("âš ï¸  åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        print(f"   è¨­å®šã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ« '{MODEL_NAME}' ã§è©¦è¡Œã—ã¾ã™...")
        return MODEL_NAME

def analyze_video(video_path: str):
    """å‹•ç”»ã‚’è§£æã—ã¦ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³JSONã‚’ç”Ÿæˆ"""
    print("\n" + "=" * 60)
    print("ğŸ“¸ã€è§£æãƒ¢ãƒ¼ãƒ‰ã€‘ãƒ­ãƒ¼ã‚«ãƒ«å‹•ç”»ã‚·ãƒ¼ãƒ³è§£æï¼ˆGeminiç‰ˆï¼‰")
    print("=" * 60)
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª
    print("\nğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªä¸­...")
    available_models = list_available_models()
    if available_models:
        print(f"âœ… åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: {', '.join(available_models)}")
    else:
        print("âš ï¸  åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    print()
    
    # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {video_path}")
    
    # MP4ãƒã‚§ãƒƒã‚¯
    if not video_path.lower().endswith('.mp4'):
        raise ValueError(f"MP4ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å¯¾å¿œã—ã¦ã„ã¾ã™: {video_path}")
    
    # å‹•ç”»ã‚’é–‹ã
    with suppress_stderr():
        cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise RuntimeError(f"å‹•ç”»ã‚’é–‹ã‘ãªã„: {video_path}")
    
    with suppress_stderr():
        fps, total_frames, duration = get_video_info(video_path)
    
    print(f"\nå‹•ç”»æƒ…å ±:")
    print(f"  ãƒ‘ã‚¹: {video_path}")
    print(f"  FPS: {fps:.2f}")
    print(f"  ç·ãƒ•ãƒ¬ãƒ¼ãƒ æ•°: {total_frames}")
    print(f"  é•·ã•: {duration:.2f}ç§’")
    
    # ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æ±ºå®š
    actual_model = get_available_model()
    print(f"  ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {actual_model}")
    
    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆ
    timestamps = []
    t = 0.0
    while t <= duration:
        timestamps.append(t)
        t += SAMPLE_INTERVAL
    
    print(f"  ğŸ“Š ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‚¹æ•°: {len(timestamps)}æš")
    print(f"  â±ï¸  ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é–“éš”: {SAMPLE_INTERVAL}ç§’")
    print(f"  ğŸ“¦ ãƒãƒƒãƒã‚µã‚¤ã‚º: {BATCH_SIZE}ãƒ•ãƒ¬ãƒ¼ãƒ /å›")
    total_batches = (len(timestamps) + BATCH_SIZE - 1) // BATCH_SIZE
    print(f"  ğŸ¤– äºˆæƒ³APIå‘¼ã³å‡ºã—: {total_batches}å›")
    print(f"  ğŸš€ ä¸¦åˆ—å®Ÿè¡Œæ•°: {MAX_CONCURRENT_REQUESTS}ï¼ˆåŒæ™‚å®Ÿè¡Œï¼‰")
    
    # äºˆæƒ³å‡¦ç†æ™‚é–“ã®è¨ˆç®—ï¼ˆä¸¦åˆ—å®Ÿè¡Œã‚’è€ƒæ…®ï¼‰
    TIME_PER_100_FRAMES = 130  # ç§’ï¼ˆ100æšã§ç´„2åˆ†10ç§’ã‚’åŸºæº–ï¼‰
    estimated_time_per_batch = (BATCH_SIZE / 100.0) * TIME_PER_100_FRAMES
    # ä¸¦åˆ—å®Ÿè¡Œã«ã‚ˆã‚Šã€å®Ÿéš›ã®å‡¦ç†æ™‚é–“ã¯çŸ­ç¸®ã•ã‚Œã‚‹
    estimated_total_time = (estimated_time_per_batch * total_batches) / MAX_CONCURRENT_REQUESTS
    
    estimated_minutes = int(estimated_total_time // 60)
    estimated_seconds = int(estimated_total_time % 60)
    print(f"  â³ äºˆæƒ³å‡¦ç†æ™‚é–“: ç´„{estimated_minutes}åˆ†{estimated_seconds}ç§’ï¼ˆä¸¦åˆ—å®Ÿè¡Œè€ƒæ…®ï¼‰")
    print(f"\nğŸ¬ AIè§£æã‚’é–‹å§‹ã—ã¾ã™...\n")
    
    # å‡¦ç†é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²
    import time
    start_time = time.time()
    
    # ã™ã¹ã¦ã®ãƒãƒƒãƒã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’äº‹å‰ã«æº–å‚™
    print(f"\nğŸ“¦ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­...")
    all_batches = []
    for batch_start in range(0, len(timestamps), BATCH_SIZE):
        batch_end = min(batch_start + BATCH_SIZE, len(timestamps))
        batch_timestamps = timestamps[batch_start:batch_end]
        
        batch_num = batch_start//BATCH_SIZE + 1
        total_batches = (len(timestamps) + BATCH_SIZE - 1)//BATCH_SIZE
        
        # ãƒãƒƒãƒå†…ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åé›†
        frames_data = []
        for t in batch_timestamps:
            with suppress_stderr():
                frame_idx = int(t * fps)
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ok, frame = cap.read()
            if not ok:
                print(f"    âš ï¸  [è­¦å‘Š] ãƒ•ãƒ¬ãƒ¼ãƒ  {frame_idx} (t={t:.1f}s) ã®èª­ã¿è¾¼ã¿å¤±æ•—")
                continue
            
            b64img = resize_and_b64(frame)
            frames_data.append({"b64_image": b64img, "timestamp": t})
        
        if frames_data:
            all_batches.append({
                "batch_num": batch_num,
                "total_batches": total_batches,
                "batch_start": batch_start,
                "batch_end": batch_end,
                "frames_data": frames_data
            })
    
    cap.release()
    
    print(f"âœ… {len(all_batches)}å€‹ã®ãƒãƒƒãƒã‚’æº–å‚™å®Œäº†")
    print(f"ğŸš€ ä¸¦åˆ—å®Ÿè¡Œé–‹å§‹ï¼ˆåŒæ™‚å®Ÿè¡Œæ•°: {MAX_CONCURRENT_REQUESTS}ï¼‰\n")
    
    # ãƒãƒƒãƒå‡¦ç†é–¢æ•°ï¼ˆä¸¦åˆ—å®Ÿè¡Œç”¨ï¼‰
    def process_batch(batch_info: Dict) -> Tuple[int, List[Tuple[Dict, str, Dict]]]:
        """å˜ä¸€ãƒãƒƒãƒã‚’å‡¦ç†ã—ã¦çµæœã‚’è¿”ã™"""
        batch_num = batch_info["batch_num"]
        total_batches = batch_info["total_batches"]
        batch_start = batch_info["batch_start"]
        batch_end = batch_info["batch_end"]
        frames_data = batch_info["frames_data"]
        
        batch_start_time = time.time()
        print(f"  ğŸ“¦ ãƒãƒƒãƒ {batch_num}/{total_batches}: ãƒ•ãƒ¬ãƒ¼ãƒ  {batch_start+1}~{batch_end}æšç›® [é–‹å§‹]")
        
        # ãƒãƒƒãƒã§ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³å–å¾—ï¼ˆãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ä»˜ãï¼‰
        api_start_time = time.time()
        print(f"    ğŸ¤– AIè§£æä¸­... ({len(frames_data)}æš)", end=" ", flush=True)
        try:
            captions, effects_list = caption_batch_vlm(frames_data, actual_model, PROMPT_NAME)
            api_elapsed = time.time() - api_start_time
            print(f"âœ“ ({api_elapsed:.1f}ç§’)")
        except Exception as e:
            print(f"\n    âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            print(f"    â³ 60ç§’å¾…æ©Ÿã—ã¦ã‹ã‚‰ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
            time.sleep(60)
            try:
                captions, effects_list = caption_batch_vlm(frames_data, actual_model, PROMPT_NAME)
                print(f"    âœ… ãƒªãƒˆãƒ©ã‚¤æˆåŠŸï¼")
            except Exception as e2:
                print(f"    âŒ ãƒªãƒˆãƒ©ã‚¤ã‚‚å¤±æ•—: {e2}")
                raise
        
        # çµæœã‚’ã¾ã¨ã‚ã‚‹
        results = []
        for frame_data, cap_text, effects_dict in zip(frames_data, captions, effects_list):
            results.append((frame_data, cap_text, effects_dict))
        
        batch_elapsed = time.time() - batch_start_time
        print(f"    âœ… ãƒãƒƒãƒ {batch_num}/{total_batches} å®Œäº† ({batch_elapsed:.1f}ç§’)")
        
        return batch_num, results
    
    # ä¸¦åˆ—å®Ÿè¡Œ
    batch_results: Dict[int, List[Tuple[Dict, str, Dict]]] = {}
    with ThreadPoolExecutor(max_workers=MAX_CONCURRENT_REQUESTS) as executor:
        # ã™ã¹ã¦ã®ãƒãƒƒãƒã‚’ä¸¦åˆ—å®Ÿè¡Œã«æŠ•å…¥
        future_to_batch = {executor.submit(process_batch, batch_info): batch_info 
                          for batch_info in all_batches}
        
        # å®Œäº†ã—ãŸãƒãƒƒãƒã‹ã‚‰é †ã«å‡¦ç†
        completed_count = 0
        for future in as_completed(future_to_batch):
            try:
                batch_num, results = future.result()
                batch_results[batch_num] = results
                completed_count += 1
                print(f"  ğŸ“Š é€²æ—: {completed_count}/{len(all_batches)}ãƒãƒƒãƒå®Œäº†\n")
            except Exception as e:
                batch_info = future_to_batch[future]
                print(f"  âŒ ãƒãƒƒãƒ {batch_info['batch_num']} ã§ã‚¨ãƒ©ãƒ¼: {e}")
                raise
    
    # ãƒãƒƒãƒçµæœã‚’æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆã—ã¦å‡¦ç†
    events: List[Dict] = []
    prev_effects: List[Tuple[str,str]] = []
    effect_start_times: Dict[Tuple[str,str], float] = {}  # å„åŠ¹æœã®é–‹å§‹æ™‚åˆ»ã‚’è¨˜éŒ²
    
    # ãƒãƒƒãƒç•ªå·ã§ã‚½ãƒ¼ãƒˆ
    sorted_batch_nums = sorted(batch_results.keys())
    for batch_num in sorted_batch_nums:
        results = batch_results[batch_num]
        
        # å„ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã¨åŠ¹æœã‚’å‡¦ç†
        for frame_data, cap_text, effects_dict in results:
            t = frame_data["timestamp"]
            
            print(f"    ğŸ’¬ t={t:.2f}s: {cap_text[:60]}{'...' if len(cap_text) > 60 else ''}")
            
            events.append({"t": round(t,3), "action":"caption", "text": cap_text})
            
            # åŠ¹æœåˆ¤å®šï¼ˆ4DX@HOMEä»•æ§˜: JSONåŠ¹æœæƒ…å ±ã‚’ä½¿ç”¨ï¼‰
            curr_effects = decide_effects(cap_text, effects_dict)
            if curr_effects:
                effect_names = []
                for e, m in curr_effects:
                    name = get_effect_display_name(e, m)
                    effect_names.append(name)
                print(f"       âš¡ {', '.join(effect_names)}")
            
            # å·®åˆ†ã‚¤ãƒ™ãƒ³ãƒˆç”Ÿæˆï¼ˆæœ€å°ç¶™ç¶šæ™‚é–“ã‚’è€ƒæ…®ï¼‰
            delta, updated_effects = diff_events(prev_effects, curr_effects, t, effect_start_times)
            events.extend(delta)
            prev_effects = updated_effects  # ç¶™ç¶šã•ã‚ŒãŸåŠ¹æœã‚’å«ã‚€
    
    if not events:
        raise RuntimeError("æœ‰åŠ¹ãƒ•ãƒ¬ãƒ¼ãƒ ãŒå–å¾—ã§ããªã‹ã£ãŸ")
    
    # çµ‚äº†æ™‚ã«ONã®ã‚‚ã®ã¯å¿…ãšstopã‚’å‡ºã™ï¼ˆæœ€å°ç¶™ç¶šæ™‚é–“ã‚’é©ç”¨ï¼‰
    end_t = timestamps[-1] if timestamps else 0.0
    
    if prev_effects:
        for eff in prev_effects:
            # æœ€å°ç¶™ç¶šæ™‚é–“ã‚’ç¢ºèª
            effect_key = f"{eff[0]}:{eff[1]}"
            start_time = effect_start_times.get(eff, 0.0)
            duration = end_t - start_time
            min_duration = MIN_DURATION.get(effect_key, 0.5)
            
            # æœ€å°ç¶™ç¶šæ™‚é–“ã«é”ã—ã¦ã„ãªã„å ´åˆã¯ã€å»¶é•·ã—ã¦ã‹ã‚‰åœæ­¢
            stop_time = max(end_t, start_time + min_duration)
            events.append({"t": round(stop_time,3), "action":"stop", "effect": eff[0], "mode": eff[1]})
    
    # æœ€çµ‚çš„ã«ã™ã¹ã¦ã®åŠ¹æœã‚’ç¢ºå®Ÿã«åœæ­¢ï¼ˆå‹•ç”»ã®æœ€å¾Œã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ï¼‰
    # ã™ã¹ã¦ã®åŠ¹æœã‚¿ã‚¤ãƒ—ã¨ãƒ¢ãƒ¼ãƒ‰ã®çµ„ã¿åˆã‚ã›ã‚’åœæ­¢
    final_stop_time = end_t + 0.1  # å°‘ã—ä½™è£•ã‚’æŒãŸã›ã‚‹
    all_effect_types = ["flash", "color", "vibration", "wind"]
    for effect_type in all_effect_types:
        if effect_type in EFFECT_DOMAIN:
            for mode in EFFECT_DOMAIN[effect_type]:
                # æ—¢ã«åœæ­¢ã‚¤ãƒ™ãƒ³ãƒˆãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€å¾Œã®0.2ç§’ä»¥å†…ï¼‰
                already_stopped = any(
                    e.get("action") == "stop" and 
                    e.get("effect") == effect_type and 
                    e.get("mode") == mode and
                    abs(e.get("t", 0) - final_stop_time) < 0.2
                    for e in events
                )
                if not already_stopped:
                    # é¢¨ã®å ´åˆã¯ "on" ã‚’ "burst" ã«å¤‰æ›ï¼ˆæ—¢å­˜JSONå½¢å¼ã«åˆã‚ã›ã‚‹ï¼‰
                    output_mode = "burst" if (effect_type == "wind" and mode == "on") else mode
                    events.append({
                        "t": round(final_stop_time, 3),
                        "action": "stop",
                        "effect": effect_type,
                        "mode": output_mode
                    })
    
    # çµæœãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs(RESULTS_DIR, exist_ok=True)
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆå‹•ç”»åã‚’ãƒ™ãƒ¼ã‚¹ã«ï¼‰
    video_name = Path(video_path).stem
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_json = os.path.join(RESULTS_DIR, f"{video_name}_timeline_{timestamp}.json")
    
    # JSONå‡ºåŠ›
    with open(output_json, "w", encoding="utf-8") as f:
        json.dump({"events": events}, f, ensure_ascii=False, indent=2)
    
    # å‡¦ç†çµ‚äº†æ™‚åˆ»ã‚’è¨˜éŒ²
    end_time = time.time()
    total_elapsed = end_time - start_time
    total_minutes = int(total_elapsed // 60)
    total_seconds = int(total_elapsed % 60)
    
    print(f"\n" + "=" * 60)
    print(f"âœ… è§£æå®Œäº†ã—ã¾ã—ãŸï¼")
    print(f"  ğŸ“„ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_json}")
    print(f"  ğŸ“Š ç·ã‚¤ãƒ™ãƒ³ãƒˆæ•°: {len(events)}å€‹")
    caption_count = sum(1 for e in events if e.get('action') == 'caption')
    effect_count = len(events) - caption_count
    print(f"  ğŸ’¬ ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³: {caption_count}å€‹")
    print(f"  âš¡ åŠ¹æœã‚¤ãƒ™ãƒ³ãƒˆ: {effect_count}å€‹")
    print(f"  â±ï¸  å®Ÿéš›ã®å‡¦ç†æ™‚é–“: {total_minutes}åˆ†{total_seconds}ç§’ ({total_elapsed:.1f}ç§’)")
    print("=" * 60)
    
    return output_json

if __name__ == "__main__":
    import sys
    
    # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’ç¢ºèªã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if len(sys.argv) > 1 and sys.argv[1] == "--list-models":
        print("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªGeminiãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªä¸­...\n")
        available = list_available_models()
        if available:
            print("âœ… åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:")
            for m in available:
                print(f"   - {m}")
            print(f"\nğŸ’¡ ç¾åœ¨ã®è¨­å®š: MODEL_NAME = '{MODEL_NAME}'")
            print(f"   ã‚³ãƒ¼ãƒ‰å†…ã® MODEL_NAME ã‚’ä¸Šè¨˜ã®ã„ãšã‚Œã‹ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚")
        else:
            print("âš ï¸  åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            print("   APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        sys.exit(0)
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸€è¦§ã‚’ç¢ºèªã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    if len(sys.argv) > 1 and sys.argv[1] == "--list-prompts":
        try:
            from prompts import list_prompts, DEFAULT_PROMPT
            print("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
            for name in list_prompts():
                marker = " (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)" if name == DEFAULT_PROMPT else ""
                print(f"   - {name}{marker}")
            print(f"\nğŸ’¡ ç¾åœ¨ã®è¨­å®š: PROMPT_NAME = {PROMPT_NAME if PROMPT_NAME else 'None (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)'}")
            print(f"   ã‚³ãƒ¼ãƒ‰å†…ã® PROMPT_NAME ã‚’ä¸Šè¨˜ã®ã„ãšã‚Œã‹ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚")
        except ImportError:
            print("âš ï¸  prompts.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        sys.exit(0)
    
    if len(sys.argv) < 2:
        print("ä½¿ã„æ–¹: python analyze_video_gemini.py <å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«>")
        print("        python analyze_video_gemini.py --list-models   # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’è¡¨ç¤º")
        print("        python analyze_video_gemini.py --list-prompts  # åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤º")
        print(f"\nåˆ©ç”¨å¯èƒ½ãªå‹•ç”» ({VIDEOS_DIR}):")
        if os.path.exists(VIDEOS_DIR):
            mp4_files = [f for f in os.listdir(VIDEOS_DIR) if f.lower().endswith('.mp4')]
            if mp4_files:
                for f in mp4_files:
                    print(f"  - {f}")
            else:
                print(f"  ï¼ˆ{VIDEOS_DIR} ã« .mp4 ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¦ãã ã•ã„ï¼‰")
        else:
            print(f"  ï¼ˆ{VIDEOS_DIR} ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼‰")
        sys.exit(1)
    
    video_file = sys.argv[1]
    
    # videosãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã®å ´åˆã¯ãƒ‘ã‚¹ã‚’è¿½åŠ 
    if not os.path.exists(video_file) and os.path.exists(os.path.join(VIDEOS_DIR, video_file)):
        video_file = os.path.join(VIDEOS_DIR, video_file)
    
    analyze_video(video_file)

